{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utilssphering\n",
    "import itertools\n",
    "import pycytominer\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoints\n",
    "\n",
    "df_replicating = pd.read_csv(\"checkpoints/moa-replicating-sphering.csv\", converters={'Null_Replicating':utilssphering.safe_literal_eval, \"Replicating\":utilssphering.safe_literal_eval)\n",
    "df_matching = pd.read_csv(\"checkpoints/moa-matching-sphering.csv\", converters={'Null_Matching':utilssphering.safe_literal_eval, \"Matching\":utilssphering.safe_literal_eval)\n",
    "\n",
    "# For some reason, adding cell counts makes the above evals fail with an \"SyntaxError: unexpected EOF while parsing\"\n",
    "# df_replicating = pd.read_csv(\"checkpoints/moa-replicating-sphering.csv\")\n",
    "# df_matching = pd.read_csv(\"checkpoints/moa-matching-sphering.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Dropping: () ----\n",
      "prop_95_matching_sphere: 23.25581395348837\n",
      "---- Dropping: ('RNA',) ----\n",
      "prop_95_matching_sphere: 23.25581395348837\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch</th>\n",
       "      <th>Assay_Plate_Barcode</th>\n",
       "      <th>num_features</th>\n",
       "      <th>dropout</th>\n",
       "      <th>n_columns</th>\n",
       "      <th>sphering</th>\n",
       "      <th>percent_replicating</th>\n",
       "      <th>percent_matching</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scope1_MolDev_10X</td>\n",
       "      <td>Plate2_PCO_6ch_4site_10XPA</td>\n",
       "      <td>4287</td>\n",
       "      <td>()</td>\n",
       "      <td>4355</td>\n",
       "      <td>True</td>\n",
       "      <td>58.888889</td>\n",
       "      <td>23.255814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scope1_MolDev_10X</td>\n",
       "      <td>Plate2_PCO_6ch_4site_10XPA</td>\n",
       "      <td>3535</td>\n",
       "      <td>('RNA',)</td>\n",
       "      <td>3590</td>\n",
       "      <td>True</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>23.255814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Batch         Assay_Plate_Barcode  num_features   dropout  \\\n",
       "0  Scope1_MolDev_10X  Plate2_PCO_6ch_4site_10XPA          4287        ()   \n",
       "1  Scope1_MolDev_10X  Plate2_PCO_6ch_4site_10XPA          3535  ('RNA',)   \n",
       "\n",
       "   n_columns  sphering  percent_replicating  percent_matching  \n",
       "0       4355      True            58.888889         23.255814  \n",
       "1       3590      True            60.000000         23.255814  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Creating dropout datasets + matrix\n",
    "\n",
    "def return_prop95(dataframe, match_or_rep=\"replicating\", enable_sphering=False):\n",
    "    \"\"\"\n",
    "    dataframe: pandas.DataFrame to find the prop95 for \n",
    "    \"\"\"\n",
    "    n_samples = 10000\n",
    "    n_replicates = 4  #number of sample replicates within each plate \n",
    "    metadata_common = 'Metadata_moa'\n",
    "    # metadata_perturbation = 'Metadata_broad_sample'\n",
    "    # group_by_feature = 'Metadata_broad_sample'\n",
    "    metadata_perturbation = 'Metadata_broad_sample'\n",
    "    group_by_feature = 'Metadata_pert_iname'\n",
    "    if match_or_rep.casefold() == \"replicating\":\n",
    "        if enable_sphering:\n",
    "            _, _, prop_95_replicating_sphere, _ = utilssphering.calculate_percent_replicating_MOA(\"\", \"\", data_df=dataframe)\n",
    "            return prop_95_replicating_sphere\n",
    "\n",
    "        if not enable_sphering: \n",
    "            plate_df = utils.remove_negcon_empty_wells(dataframe)\n",
    "            replicate_corr = list(utils.corr_between_replicates(plate_df, group_by_feature))\n",
    "            null_replicating = list(utils.corr_between_non_replicates(plate_df, n_samples=n_samples, n_replicates=n_replicates, metadata_compound_name=group_by_feature))\n",
    "            prop_95_replicating, _ = utils.percent_score(null_replicating, replicate_corr, how='right')\n",
    "            return prop_95_replicating\n",
    "\n",
    "    if match_or_rep.casefold() == \"matching\":\n",
    "        if enable_sphering:\n",
    "            _, _, prop_95_matching_sphere, _ = utilssphering.calculate_percent_matching_MOA(\"\", \"\", data_df=dataframe)\n",
    "            print(f\"prop_95_matching_sphere: {prop_95_matching_sphere}\")\n",
    "            return prop_95_matching_sphere\n",
    "\n",
    "        if not enable_sphering:\n",
    "            plate_df = utils.remove_negcon_empty_wells(dataframe)\n",
    "            matching_corr = list(utils.corr_between_perturbation_pairs(plate_df, 'Metadata_moa', 'Metadata_broad_sample'))\n",
    "            null_matching = list(utils.corr_between_perturbation_non_pairs(plate_df, n_samples=n_samples, metadata_common=metadata_common, metadata_perturbation=metadata_perturbation))\n",
    "            prop_95_matching, _ = utils.percent_score(null_matching, matching_corr, how='right')\n",
    "            return prop_95_matching\n",
    "\n",
    "\n",
    "def do_feature_select(plate_df):\n",
    "    \"\"\"\n",
    "    Find the column names that are CellProfiler features. Eg. column names\n",
    "    that start with \"Nuclei\" or \"Cytoplasm\"\n",
    "    \"\"\"\n",
    "    # feature_select_features = pycytominer.cyto_utils.infer_cp_features(\n",
    "    #     plate_df\n",
    "    # )\n",
    "    # For all of the cellprofiler features, perform these operations on them\n",
    "    return pycytominer.feature_select(\n",
    "        profiles=plate_df,\n",
    "        # features=feature_select_features,\n",
    "        # operation=['variance_threshold','correlation_threshold',\n",
    "        # 'drop_na_columns','blocklist']\n",
    "    )\n",
    "\n",
    "def all_combo_dropouts_in_a_category(category_list,outfile,subsample=None):\n",
    "    \"\"\"\n",
    "    Create a database with dropped out features\n",
    "\n",
    "    category_list: the categories to drop out (for example, Nuclei, Cytoplasm, Cells)\n",
    "    outfile: save csv path\n",
    "    \"\"\"\n",
    "    # For all of the categories, find all possible combinations with itertools.combinations\n",
    "    to_try = [y for x in range(len(category_list)+1) for y in list(set(itertools.combinations(category_list,x)))]\n",
    "\n",
    "    # If the output csv already exists, check what dropouts have already been tried\n",
    "    # Don't try them again\n",
    "    if os.path.exists(outfile):\n",
    "        dropout_df = pd.read_csv(outfile)\n",
    "        tried=list(dropout_df['Dropout'])\n",
    "        print(f\"Already try {tried},skipping\")\n",
    "        to_try = [x for x in to_try if str(x) not in tried]\n",
    "    # Otherwise, dropout columns will be generated from scratch\n",
    "    else:\n",
    "        dropout_df = pd.DataFrame()\n",
    "    \n",
    "    # For the given categories, go through each combination (eg. ('Cells', 'Cytoplasm'), ('Nuclei', 'Cytoplasm') etc.)\n",
    "    for eachdropout in to_try:\n",
    "        # Get what columns are expected. I don't like this method\n",
    "        normalized_master = pd.read_csv('../profiles-pilots/profiles/Stain5_CondC_Standard/BR00120274/BR00120274_normalized_negcon.csv.gz')\n",
    "        col_list = normalized_master.columns\n",
    "        if subsample:\n",
    "             for each_item in subsample:\n",
    "                metadata_list = [x for x in col_list if 'Metadata' in x] \n",
    "                col_list = metadata_list+[x for x in col_list if each_item in x]\n",
    "        for each_item in eachdropout:\n",
    "            # Create a list of columns that DOESN'T contain the categories being iterated\n",
    "            # Thus this will iterate over all categories (eg. nuclei, cell, cytoplasm) and\n",
    "            # drop all of the column names\n",
    "            col_list = [x for x in col_list if each_item not in x]\n",
    "        dropout_dict = {}\n",
    "        temp_dropout_dict = {}\n",
    "        # Code unique to this dataset. Iterate through plates\n",
    "        for eachplate in range(70,78):\n",
    "            try:\n",
    "                # Read only the columns previously defined for each plate being iterated over\n",
    "                # Again, don't like this hardcoding. Should be some sort of os.walk situation\n",
    "                normalized = pandas.read_csv(\n",
    "                    f'../profiles-pilots/profiles/Stain5_CondC_Standard/BR001202{eachplate}/BR001202{eachplate}_normalized_negcon.csv.gz',\n",
    "                    usecols=col_list)\n",
    "                # For the loaded dataset, calculate feature selection AFTER column dropout\n",
    "                feature_select = do_feature_select(normalized)\n",
    "                temp_dropout_dict[f'{eachplate}_featnum']=len(feature_select.columns)\n",
    "                # Now, calculate the perc_rep for the dropout dataset \n",
    "                ### NOTE: in utilsphering, calculate_percent_replicating_MOA has been updated to return\n",
    "                ### replicate_corr, null_corr, prop_95, value_95_replicating\n",
    "                ### In this example, calculate_percent_replicating_MOA is **only returning prop_95**\n",
    "                dropout_dict[f'BR001202{eachplate}']= calculate_percent_replicating_MOA('','',data_df=feature_select)\n",
    "            except:\n",
    "                dropout_dict[f'BR001202{eachplate}']=0\n",
    "        # Convert the calculated perc_rep into np.array for each dropout \n",
    "        results_array = np.array(list(dropout_dict.values()))\n",
    "        for k,v in temp_dropout_dict.items():\n",
    "            dropout_dict[k]=v\n",
    "        # For the dropout dataset created, calculate the mean perc_replicating for ALL of the plates\n",
    "        # Why all of the plates? Are these replicates?\n",
    "        # Means are calculated within each dropout group\n",
    "        dropout_dict['Mean']=results_array.mean()\n",
    "        dropout_dict['Median']=np.median(results_array)\n",
    "        dropout_dict['Standard deviation']=np.std(results_array)\n",
    "        dropout_dict['Dropout']=eachdropout\n",
    "        dropout_dict['Remaining'] = [x for x in category_list if x not in eachdropout]\n",
    "        dropout_dict['n_columns']=len(col_list)\n",
    "        dropout_df = dropout_df.append(dropout_dict,ignore_index=True)\n",
    "        print(eachdropout,dropout_dict['Mean'])\n",
    "        dropout_df.to_csv(outfile,index=False)\n",
    "    print(dropout_df['Mean'].describe())\n",
    "    print(dropout_df['Median'].describe())\n",
    "\n",
    "def category_dropout(\n",
    "    experiment_metadata,\n",
    "    profile_parent_dir, \n",
    "    category_list, \n",
    "    match_or_rep_or_both=\"replicating\",\n",
    "    enable_sphering=\"both\", \n",
    "    outfile=None\n",
    "):\n",
    "    rep_df_list = list()\n",
    "    match_df_list = list()\n",
    "\n",
    "    # Check if dropout has previously been performed\n",
    "    # if os.path.exists(outfile):\n",
    "    #     # Limitation of this implementation:\n",
    "    #     # If you switch from sphering to not sphering, this will fail to \n",
    "    #     # run the analysis without sphering as it only checks the 'dropout'\n",
    "    #     # column combinations and not any other column (such as if sphering was T/F).\n",
    "    #     dropout_df = pd.read_csv(outfile)\n",
    "    #     rep_df_list.append(dropout_df)\n",
    "    #     match_df_list.append(dropout_df)\n",
    "    #     tried=list(dropout_df[\"dropout\"])\n",
    "    #     print(f\"Already tried {tried}. Skipping.\")\n",
    "    #     possible_combinations = [x for x in possible_combinations if str(x) not in tried]\n",
    "    #     # Otherwise, dropout columns will be generated from scratch\n",
    "\n",
    "    for ind, row in experiment_metadata.iterrows():\n",
    "        for root, dirs, files in os.walk(profile_parent_dir):\n",
    "            load_path = os.path.join(profile_parent_dir, row[\"Batch\"], row[\"Assay_Plate_Barcode\"],  row[\"Assay_Plate_Barcode\"]+\"_normalized_negcon.csv.gz\")\n",
    "            for file in files:\n",
    "                if os.path.join(root, file) == load_path:\n",
    "                    load_df = pd.read_csv(load_path)\n",
    "                    input_columns = load_df.columns\n",
    "                    possible_combinations = [y for x in range(len(category_list)+1) for y in list(set(itertools.combinations(category_list,x)))]\n",
    "                    if len(possible_combinations) == 0:\n",
    "                        # Either no combinations available or they're already present in the outfile\n",
    "                        print(\"All combinations already computed\")\n",
    "                        return\n",
    "                    # Iterate through the combination to dropout\n",
    "                    for dropout_group in possible_combinations: \n",
    "                        col_list = input_columns\n",
    "                        # Within the droupout group, find the column to actually drop\n",
    "                        for each_item in dropout_group:\n",
    "                            # Only keep columns that don't contain the dropout\n",
    "                            col_list = [x for x in col_list if each_item not in x]\n",
    "                        print(f\"---- Dropping: {dropout_group} ----\")\n",
    "                        try:\n",
    "                            dropped_dataframe = pd.DataFrame(load_df[col_list])\n",
    "                            feature_select = do_feature_select(dropped_dataframe)\n",
    "                        except Exception as e:\n",
    "                            print(e)\n",
    "                            feature_select = 0\n",
    "                        # return feature_select\n",
    "                        if match_or_rep_or_both.casefold() == \"replicating\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "                            if enable_sphering.casefold() == \"yes\" or enable_sphering.casefold() == \"both\":\n",
    "                                try:\n",
    "                                    # Added to tackle an issue where longer dropout runs would error out due to NaN input\n",
    "                                    # Unsure of the source of the NaN input. This is a temporary solution.\n",
    "                                    prop_95 = return_prop95(feature_select, match_or_rep=\"replicating\", enable_sphering=True)\n",
    "                                except:\n",
    "                                    prop_95 = 0\n",
    "                                _df = pd.DataFrame({\n",
    "                                    \"Batch\": row[\"Batch\"],\n",
    "                                    \"Assay_Plate_Barcode\": row[\"Assay_Plate_Barcode\"],\n",
    "                                    \"num_features\": len(feature_select.columns),\n",
    "                                    \"dropout\": str(dropout_group),\n",
    "                                    \"n_columns\": len(col_list),\n",
    "                                    \"sphering\": True,\n",
    "                                    \"percent_replicating\": [prop_95]\n",
    "                                })\n",
    "                                rep_df_list.append(_df)\n",
    "                            if enable_sphering.casefold() == \"no\" or enable_sphering.casefold() == \"both\":\n",
    "                                try:\n",
    "                                    prop_95 = return_prop95(feature_select, match_or_rep=\"replicating\", enable_sphering=False)\n",
    "                                except:\n",
    "                                    prop_95 = 0                \n",
    "                                _df = pd.DataFrame({\n",
    "                                    \"Batch\": row[\"Batch\"],\n",
    "                                    \"Assay_Plate_Barcode\": row[\"Assay_Plate_Barcode\"],\n",
    "                                    \"num_features\": len(feature_select.columns),\n",
    "                                    \"dropout\": str(dropout_group),\n",
    "                                    \"n_columns\": len(col_list),\n",
    "                                    \"sphering\": False,\n",
    "                                    \"percent_replicating\": [prop_95]\n",
    "                                })\n",
    "                                rep_df_list.append(_df)\n",
    "                        if match_or_rep_or_both.casefold() == \"matching\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "                            if enable_sphering.casefold() == \"yes\" or enable_sphering.casefold() == \"both\":\n",
    "                                try:\n",
    "                                    prop_95 = return_prop95(feature_select, match_or_rep=\"matching\", enable_sphering=True)\n",
    "                                except:\n",
    "                                    prop_95 = 0\n",
    "                                _df = pd.DataFrame({\n",
    "                                    \"Batch\": row[\"Batch\"],\n",
    "                                    \"Assay_Plate_Barcode\": row[\"Assay_Plate_Barcode\"],\n",
    "                                    \"num_features\": len(feature_select.columns),\n",
    "                                    \"dropout\": str(dropout_group),\n",
    "                                    \"n_columns\": len(col_list),\n",
    "                                    \"sphering\": True,\n",
    "                                    \"percent_matching\": [prop_95]\n",
    "                                })\n",
    "                                match_df_list.append(_df)\n",
    "                            if enable_sphering.casefold() == \"no\" or enable_sphering.casefold() == \"both\":\n",
    "                                try:\n",
    "                                    prop_95 = return_prop95(feature_select, match_or_rep=\"matching\", enable_sphering=False)\n",
    "                                except:\n",
    "                                    prop_95 = 0\n",
    "                                _df = pd.DataFrame({\n",
    "                                    \"Batch\": row[\"Batch\"],\n",
    "                                    \"Assay_Plate_Barcode\": row[\"Assay_Plate_Barcode\"],\n",
    "                                    \"num_features\": len(feature_select.columns),\n",
    "                                    \"dropout\": str(dropout_group),\n",
    "                                    \"n_columns\": len(col_list),\n",
    "                                    \"sphering\": False,\n",
    "                                    \"percent_matching\": [prop_95],\n",
    "                                })\n",
    "                                match_df_list.append(_df)\n",
    "            \n",
    "        # Concatenate the data\n",
    "        if match_or_rep_or_both.casefold() == \"replicating\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "            rep_df = pd.concat(rep_df_list, ignore_index=True)\n",
    "        if match_or_rep_or_both.casefold() == \"matching\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "            match_df = pd.concat(match_df_list, ignore_index=True)\n",
    "                    \n",
    "        # Merge so perc rep and match is in the same place\n",
    "        if match_or_rep_or_both.casefold() == \"both\":\n",
    "            merged_df = rep_df.merge(match_df, how=\"inner\")\n",
    "            if outfile is not None:\n",
    "                merged_df.to_csv(outfile,index=False)\n",
    "            return merged_df\n",
    "        if match_or_rep_or_both.casefold() == \"replicating\":\n",
    "            if outfile is not None:\n",
    "                rep_df.to_csv(outfile,index=False)\n",
    "            return rep_df\n",
    "        if match_or_rep_or_both.casefold() == \"matching\":\n",
    "            if outfile is not None:\n",
    "                match_df.to_csv(outfile,index=False)\n",
    "            return match_df\n",
    "        \n",
    "# TODO: Check that this is accurately dropping, integrate with os.walk, integrate with heatmap matrix\n",
    "# No need to integrate with os.walk. Use metadata csv\n",
    "\n",
    "\n",
    "# 1. Feed experiment_metadata\n",
    "# 2. Finds normalized negcon file, performs feature select\n",
    "\n",
    "\n",
    "experiment_metadata = pd.read_csv(\"output/all-profile-metadata.csv\")\n",
    "profile_parent_dir = \"../jump-scope/profiles\"\n",
    "\n",
    "drops = category_dropout(experiment_metadata.loc[:2,:], profile_parent_dir, [\"RNA\"], \"both\", \"yes\", \"test.csv\")\n",
    "drops\n",
    "# ['Nuclei','Cells','Cytoplasm']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Yokogawa_US\n",
      "---- Dropping: () ----\n",
      "../jump-scope/profiles/Scope1_Yokogawa_US_20X_6Ch_BRO0117059/BRO0117059_20X/BRO0117059_20X_normalized_negcon.csv.gz\n",
      "---- Dropping: ('RNA',) ----\n",
      "../jump-scope/profiles/Scope1_Yokogawa_US_20X_6Ch_BRO0117059/BRO0117059_20X/BRO0117059_20X_normalized_negcon.csv.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        Vendor                                  Batch  \\\n",
       " 0  Yokogawa_US  Scope1_Yokogawa_US_20X_6Ch_BRO0117059   \n",
       " 1  Yokogawa_US  Scope1_Yokogawa_US_20X_6Ch_BRO0117059   \n",
       " \n",
       "                Plate_Map_Name Assay_Plate_Barcode  Modality  Images_per_well  \\\n",
       " 0  JUMP-MOA_compound_platemap      BRO0117059_20X  Confocal                9   \n",
       " 1  JUMP-MOA_compound_platemap      BRO0117059_20X  Confocal                9   \n",
       " \n",
       "    Sites-SubSampled  Binning  Magnification  Number_of_channels  ...  \\\n",
       " 0               NaN        1             20                   6  ...   \n",
       " 1               NaN        1             20                   6  ...   \n",
       " \n",
       "     Size_MB Size_MB_std num_features   dropout n_columns  \\\n",
       " 0  7.954439    0.000583          467        ()      4267   \n",
       " 1  7.954439    0.000583          421  ('RNA',)      3532   \n",
       " \n",
       "                                          Replicating  \\\n",
       " 0  [0.20376962714650543, 0.46971569908024957, 0.8...   \n",
       " 1  [0.20431095810594152, 0.45765328128940497, 0.8...   \n",
       " \n",
       "                                     Null_Replicating  Percent_Replicating  \\\n",
       " 0  [0.24000650347763558, -0.004476207148594095, 0...            62.222222   \n",
       " 1  [0.19588841992150208, 0.2711050921655639, 0.11...            62.222222   \n",
       " \n",
       "    Value_95  sphering  \n",
       " 0  0.275208      True  \n",
       " 1  0.292703      True  \n",
       " \n",
       " [2 rows x 28 columns],\n",
       "         Vendor                                  Batch  \\\n",
       " 0  Yokogawa_US  Scope1_Yokogawa_US_20X_6Ch_BRO0117059   \n",
       " 1  Yokogawa_US  Scope1_Yokogawa_US_20X_6Ch_BRO0117059   \n",
       " \n",
       "                Plate_Map_Name Assay_Plate_Barcode  Modality  Images_per_well  \\\n",
       " 0  JUMP-MOA_compound_platemap      BRO0117059_20X  Confocal                9   \n",
       " 1  JUMP-MOA_compound_platemap      BRO0117059_20X  Confocal                9   \n",
       " \n",
       "    Sites-SubSampled  Binning  Magnification  Number_of_channels  ...  \\\n",
       " 0               NaN        1             20                   6  ...   \n",
       " 1               NaN        1             20                   6  ...   \n",
       " \n",
       "    vs-brightfield simultaneous-excitation sites   Size_MB Size_MB_std  \\\n",
       " 0             yes                     4.0     9  7.954439    0.000583   \n",
       " 1             yes                     4.0     9  7.954439    0.000583   \n",
       " \n",
       "                                             Matching  \\\n",
       " 0  [0.7022699302582183, 0.022433167848663622, -0....   \n",
       " 1  [0.7046747894638048, 0.032263162401999695, -0....   \n",
       " \n",
       "                                        Null_Matching  Percent_Matching  \\\n",
       " 0  [-0.0011658719448509412, 0.12645353965290998, ...         23.255814   \n",
       " 1  [0.10538751556351994, 0.3187548217813996, 0.05...         20.930233   \n",
       " \n",
       "    Value_95  sphering  \n",
       " 0  0.414378      True  \n",
       " 1  0.450440      True  \n",
       " \n",
       " [2 rows x 25 columns])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def do_feature_select(plate_df):\n",
    "    \"\"\"\n",
    "    Find the column names that are CellProfiler features. Eg. column names\n",
    "    that start with \"Nuclei\" or \"Cytoplasm\"\n",
    "    \"\"\"\n",
    "    feature_select_features = pycytominer.cyto_utils.infer_cp_features(\n",
    "        plate_df\n",
    "    )\n",
    "    # For all of the cellprofiler features, perform these operations on them\n",
    "    return pycytominer.feature_select(\n",
    "        profiles=plate_df,\n",
    "        features=feature_select_features,\n",
    "        operation=['variance_threshold','correlation_threshold',\n",
    "        'drop_na_columns','blocklist']\n",
    "    )\n",
    "\n",
    "def create_moa_dataframe(experiment_metadata, profile_parent_dir, batch_col=\"Batch\", match_or_rep_or_both=\"replicating\", enable_sphering=\"both\", dropout_cols=None):\n",
    "    \"\"\"\n",
    "    batch_col is the name of the column to distinguish the profile parent folder. Eg. \"Scope1_MolDev_10X\" or \"1siteSubSample_Scope1_MolDev_10X\"\n",
    "    Output df will also use this batch_col name\n",
    "    \"\"\"\n",
    "    n_samples = 10000\n",
    "    n_replicates = 4  # number of sample replicates within each plate \n",
    "    metadata_common = 'Metadata_moa'\n",
    "    metadata_perturbation = 'Metadata_broad_sample'\n",
    "    group_by_feature = 'Metadata_pert_iname'\n",
    "\n",
    "    corr_replicating_list = list()\n",
    "    corr_matching_list = list()\n",
    "    passed_data = list()\n",
    "\n",
    "    for ind, a_vendor in enumerate(experiment_metadata[\"Vendor\"].unique()):\n",
    "        print(f\"Processing {a_vendor}\")\n",
    "        vendor_data = experiment_metadata.loc[experiment_metadata[\"Vendor\"] == a_vendor]\n",
    "        for a_batch in vendor_data[batch_col].unique():\n",
    "            batch_data = vendor_data.loc[vendor_data[batch_col] == a_batch]\n",
    "            for a_plate in batch_data[\"Assay_Plate_Barcode\"].unique():\n",
    "                # plate_data = batch_data.loc[batch_data[\"Assay_Plate_Barcode\"] == a_plate]\n",
    "                data_path = os.path.join(profile_parent_dir, a_batch, a_plate, a_plate+\"_normalized_negcon.csv.gz\")\n",
    "                load_data = pd.read_csv(data_path)\n",
    "                if dropout_cols is not None:\n",
    "                    input_columns = load_data.columns\n",
    "                    possible_combinations = [y for x in range(len(dropout_cols)+1) for y in list(set(itertools.combinations(dropout_cols,x)))]\n",
    "                    if len(possible_combinations) == 0:\n",
    "                        # Either no combinations available or they're already present in the outfile\n",
    "                        print(\"All combinations already computed\")\n",
    "                        return\n",
    "                    # Iterate through the combination to dropout\n",
    "                    for dropout_group in possible_combinations: \n",
    "                        col_list = input_columns\n",
    "                        # Within the droupout group, find the column to actually drop\n",
    "                        for each_item in dropout_group:\n",
    "                            # Only keep columns that don't contain the dropout\n",
    "                            col_list = [x for x in col_list if each_item not in x]\n",
    "                        print(f\"---- Dropping: {dropout_group} ----\")\n",
    "                        try:\n",
    "                            dropped_df = pd.DataFrame(load_data[col_list])\n",
    "                            feature_selected_df = do_feature_select(dropped_df)\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error: {e}\")\n",
    "                            feature_select = 0\n",
    "                        print(data_path)\n",
    "                        try:\n",
    "                            if match_or_rep_or_both.casefold() == \"replicating\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "                                if enable_sphering.casefold() == \"yes\" or enable_sphering.casefold() == \"both\":\n",
    "                                    sphere_bool = True\n",
    "                                    replicate_corr_sphere, null_replicating_sphere, prop_95_replicating_sphere, value_95_replicating_sphere = utilssphering.calculate_percent_replicating_MOA(\"\", \"\", data_df=feature_selected_df)\n",
    "                                    corr_replicating_list.append(pd.DataFrame({'Vendor': a_vendor,\n",
    "                                                                                batch_col: a_batch,\n",
    "                                                                                'Assay_Plate_Barcode': a_plate,\n",
    "                                                                                \"num_features\": len(feature_selected_df.columns),\n",
    "                                                                                \"dropout\": str(dropout_group),\n",
    "                                                                                \"n_columns\": len(col_list),\n",
    "                                                                                'Replicating':[replicate_corr_sphere],\n",
    "                                                                                'Null_Replicating':[null_replicating_sphere],\n",
    "                                                                                'Percent_Replicating':prop_95_replicating_sphere,\n",
    "                                                                                'Value_95':value_95_replicating_sphere,\n",
    "                                                                                'sphering': sphere_bool}, index=[ind]))\n",
    "\n",
    "                                if enable_sphering.casefold() == \"no\" or enable_sphering.casefold() == \"both\": \n",
    "                                    sphere_bool = False\n",
    "                                    plate_df = utils.remove_negcon_empty_wells(feature_selected_df)\n",
    "                                    replicate_corr = list(utils.corr_between_replicates(plate_df, group_by_feature))\n",
    "                                    null_replicating = list(utils.corr_between_non_replicates(plate_df, n_samples=n_samples, n_replicates=n_replicates, metadata_compound_name=group_by_feature))\n",
    "                                    prop_95_replicating, value_95_replicating = utils.percent_score(null_replicating, replicate_corr, how='right')\n",
    "                                    corr_replicating_list.append(pd.DataFrame({'Vendor': a_vendor,\n",
    "                                                                                batch_col: a_batch,\n",
    "                                                                                'Assay_Plate_Barcode': a_plate,\n",
    "                                                                                'Replicating':[replicate_corr],\n",
    "                                                                                'Null_Replicating':[null_replicating],\n",
    "                                                                                'Percent_Replicating':prop_95_replicating,\n",
    "                                                                                'Value_95':value_95_replicating,\n",
    "                                                                                'sphering': sphere_bool}, index=[ind]))\n",
    "\n",
    "                            if match_or_rep_or_both.casefold() == \"matching\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "                                if enable_sphering.casefold() == \"yes\" or enable_sphering.casefold() == \"both\":\n",
    "                                    sphere_bool = True\n",
    "                                    matching_corr_sphere, null_matching_sphere, prop_95_matching_sphere, value_95_matching_sphere = utilssphering.calculate_percent_matching_MOA(\"\", \"\", data_df=feature_selected_df)\n",
    "                                    corr_matching_list.append(pd.DataFrame({'Vendor': a_vendor,\n",
    "                                                                            batch_col: a_batch,\n",
    "                                                                            'Assay_Plate_Barcode': a_plate,\n",
    "                                                                            'Matching':[matching_corr_sphere],\n",
    "                                                                            'Null_Matching':[null_matching_sphere],\n",
    "                                                                            'Percent_Matching':prop_95_matching_sphere,\n",
    "                                                                            'Value_95':value_95_matching_sphere,\n",
    "                                                                            'sphering': sphere_bool}, index=[ind]))\n",
    "                                \n",
    "                                if enable_sphering.casefold() == \"no\" or enable_sphering.casefold() == \"both\": \n",
    "                                    sphere_bool = False\n",
    "                                    plate_df = utils.remove_negcon_empty_wells(feature_selected_df)\n",
    "                                    matching_corr = list(utils.corr_between_perturbation_pairs(plate_df, 'Metadata_moa', 'Metadata_broad_sample'))\n",
    "                                    null_matching = list(utils.corr_between_perturbation_non_pairs(plate_df, n_samples=n_samples, metadata_common=metadata_common, metadata_perturbation=metadata_perturbation))\n",
    "                                    prop_95_matching, value_95_matching = utils.percent_score(null_matching, matching_corr, how='right')\n",
    "                                    corr_matching_list.append(pd.DataFrame({'Vendor': a_vendor,\n",
    "                                                                            batch_col: a_batch,\n",
    "                                                                            'Assay_Plate_Barcode': a_plate,\n",
    "                                                                            'Matching':[matching_corr],\n",
    "                                                                            'Null_Matching':[null_matching],\n",
    "                                                                            'Percent_Matching':prop_95_matching,\n",
    "                                                                            'Value_95':value_95_matching,\n",
    "                                                                            'sphering': sphere_bool}, index=[ind]))\n",
    "                        except Exception as e:\n",
    "                            logging.error(f\"Passed: {data_path}\", exc_info=e)\n",
    "    # Concatenate the data\n",
    "    if match_or_rep_or_both.casefold() == \"replicating\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "        corr_replicating_df = pd.concat(corr_replicating_list, ignore_index=True)\n",
    "    if match_or_rep_or_both.casefold() == \"matching\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "        corr_matching_df = pd.concat(corr_matching_list, ignore_index=True)\n",
    "                \n",
    "    # Merge metadata with output dataframes\n",
    "    merge_columns = ['Vendor', batch_col, 'Assay_Plate_Barcode']\n",
    "    if match_or_rep_or_both.casefold() == \"both\":\n",
    "        corr_replicating_df = experiment_metadata.merge(corr_replicating_df, how=\"inner\", on=merge_columns)\n",
    "        corr_matching_df = experiment_metadata.merge(corr_matching_df, how=\"inner\", on=merge_columns)\n",
    "        return corr_replicating_df, corr_matching_df\n",
    "    if match_or_rep_or_both.casefold() == \"replicating\":\n",
    "        return experiment_metadata.merge(corr_replicating_df, how=\"inner\", on=merge_columns)\n",
    "    elif match_or_rep_or_both.casefold() == \"matching\":\n",
    "        return experiment_metadata.merge(corr_matching_df, how=\"inner\", on=merge_columns)\n",
    "\n",
    "\n",
    "experiment_metadata = pd.read_csv(\"output/all-profile-metadata.csv\")\n",
    "profile_parent_dir = \"../jump-scope/profiles\"\n",
    "# experiment_metadata = experiment_metadata[(experiment_metadata[\"Assay_Plate_Barcode\"] == \"BRO0117059_20X\") & (~experiment_metadata[\"Batch\"].str.contains(\"siteSub\"))]\n",
    "\n",
    "df = create_moa_dataframe(experiment_metadata, \"../jump-scope/profiles\", match_or_rep_or_both=\"both\", enable_sphering=\"yes\", dropout_cols=['RNA'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch</th>\n",
       "      <th>Assay_Plate_Barcode</th>\n",
       "      <th>Percent_Replicating</th>\n",
       "      <th>dropout</th>\n",
       "      <th>n_columns</th>\n",
       "      <th>sphering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Scope1_Yokogawa_US_20X_6Ch_BRO0117059</td>\n",
       "      <td>BRO0117059_20X</td>\n",
       "      <td>62.222222</td>\n",
       "      <td>()</td>\n",
       "      <td>4267</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Scope1_Yokogawa_US_20X_6Ch_BRO0117059</td>\n",
       "      <td>BRO0117059_20X</td>\n",
       "      <td>62.222222</td>\n",
       "      <td>('RNA',)</td>\n",
       "      <td>3532</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Batch Assay_Plate_Barcode  \\\n",
       "0  Scope1_Yokogawa_US_20X_6Ch_BRO0117059      BRO0117059_20X   \n",
       "1  Scope1_Yokogawa_US_20X_6Ch_BRO0117059      BRO0117059_20X   \n",
       "\n",
       "   Percent_Replicating   dropout  n_columns  sphering  \n",
       "0            62.222222        ()       4267      True  \n",
       "1            62.222222  ('RNA',)       3532      True  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"Batch\", \"Assay_Plate_Barcode\", \"Percent_Replicating\", \"dropout\", \"n_columns\", \"sphering\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch</th>\n",
       "      <th>Assay_Plate_Barcode</th>\n",
       "      <th>Percent_Replicating</th>\n",
       "      <th>sphering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Scope1_Yokogawa_US_20X_6Ch_BRO0117059</td>\n",
       "      <td>BRO0117059_20X</td>\n",
       "      <td>61.111111</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Batch Assay_Plate_Barcode  \\\n",
       "102  Scope1_Yokogawa_US_20X_6Ch_BRO0117059      BRO0117059_20X   \n",
       "\n",
       "     Percent_Replicating  sphering  \n",
       "102            61.111111      True  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_rep_df = pd.read_csv(\"checkpoints/match_rep_df.csv\")\n",
    "match_rep_df[\n",
    "    (match_rep_df[\"Assay_Plate_Barcode\"] == \"BRO0117059_20X\") & \n",
    "    (~match_rep_df[\"Batch\"].str.contains(\"siteSub\")) &\n",
    "    (match_rep_df[\"sphering\"] == True)\n",
    "    ][[\"Batch\", \"Assay_Plate_Barcode\", \"Percent_Replicating\", \"sphering\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vendor</th>\n",
       "      <th>Batch</th>\n",
       "      <th>Plate_Map_Name</th>\n",
       "      <th>Assay_Plate_Barcode</th>\n",
       "      <th>Modality</th>\n",
       "      <th>Images_per_well</th>\n",
       "      <th>Sites-SubSampled</th>\n",
       "      <th>Binning</th>\n",
       "      <th>Magnification</th>\n",
       "      <th>Number_of_channels</th>\n",
       "      <th>z_plane</th>\n",
       "      <th>BF_Zplanes</th>\n",
       "      <th>spinning-disc</th>\n",
       "      <th>aperture</th>\n",
       "      <th>dry-immersion</th>\n",
       "      <th>vs-brightfield</th>\n",
       "      <th>simultaneous-excitation</th>\n",
       "      <th>sites</th>\n",
       "      <th>Size_MB</th>\n",
       "      <th>Size_MB_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MolDev</td>\n",
       "      <td>Scope1_MolDev_10X</td>\n",
       "      <td>JUMP-MOA_compound_platemap</td>\n",
       "      <td>Plate2_PCO_6ch_4site_10XPA</td>\n",
       "      <td>Confocal</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>0.45</td>\n",
       "      <td>dry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>52.476334</td>\n",
       "      <td>0.000144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MolDev</td>\n",
       "      <td>Scope1_MolDev_10X</td>\n",
       "      <td>JUMP-MOA_compound_platemap</td>\n",
       "      <td>Plate3_PCO_6ch_4site_10XPA_Crest</td>\n",
       "      <td>Confocal</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.45</td>\n",
       "      <td>dry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>52.476514</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MolDev</td>\n",
       "      <td>Scope1_MolDev_10X_4siteZ</td>\n",
       "      <td>JUMP-MOA_compound_platemap</td>\n",
       "      <td>Plate3_PCO_6ch_4site_10XPA_Crestz</td>\n",
       "      <td>Confocal</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.45</td>\n",
       "      <td>dry</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>52.476631</td>\n",
       "      <td>0.000142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Vendor                     Batch              Plate_Map_Name  \\\n",
       "0  MolDev         Scope1_MolDev_10X  JUMP-MOA_compound_platemap   \n",
       "1  MolDev         Scope1_MolDev_10X  JUMP-MOA_compound_platemap   \n",
       "2  MolDev  Scope1_MolDev_10X_4siteZ  JUMP-MOA_compound_platemap   \n",
       "\n",
       "                 Assay_Plate_Barcode  Modality  Images_per_well  \\\n",
       "0         Plate2_PCO_6ch_4site_10XPA  Confocal                4   \n",
       "1   Plate3_PCO_6ch_4site_10XPA_Crest  Confocal                4   \n",
       "2  Plate3_PCO_6ch_4site_10XPA_Crestz  Confocal                4   \n",
       "\n",
       "   Sites-SubSampled  Binning  Magnification  Number_of_channels  z_plane  \\\n",
       "0               NaN        1             10                   6        1   \n",
       "1               NaN        1             10                   6        1   \n",
       "2               NaN        1             10                   6        3   \n",
       "\n",
       "  BF_Zplanes spinning-disc  aperture dry-immersion vs-brightfield  \\\n",
       "0        NaN            no      0.45           dry            NaN   \n",
       "1        NaN           yes      0.45           dry            NaN   \n",
       "2        NaN           yes      0.45           dry            NaN   \n",
       "\n",
       "   simultaneous-excitation  sites    Size_MB  Size_MB_std  \n",
       "0                      NaN      4  52.476334     0.000144  \n",
       "1                      NaN      4  52.476514     0.000183  \n",
       "2                      NaN      4  52.476631     0.000142  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "experiment_metadata = pd.read_csv(\"output/all-profile-metadata.csv\")\n",
    "experiment_metadata.loc[:2,:]\n",
    "# profile_parent_dir = \"../jump-scope/profiles\"\n",
    "\n",
    "# count = 0\n",
    "# for ind, row in experiment_metadata.iterrows():\n",
    "#     for root, dirs, files in os.walk(profile_parent_dir):\n",
    "#         load_path = os.path.join(profile_parent_dir, row[\"Batch\"], row[\"Assay_Plate_Barcode\"],  row[\"Assay_Plate_Barcode\"]+\"_normalized_negcon.csv.gz\")\n",
    "#         for file in files:\n",
    "#             if os.path.join(root, file) == load_path:\n",
    "#                 count += 1\n",
    "#                 print(load_path)\n",
    "\n",
    "# print(experiment_metadata.shape, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather the dropout data\n",
    "df_list = list()\n",
    "t = pd.DataFrame()\n",
    "_, parent_folders, _ = next(os.walk(\"../jump-scope/profiles/\"))\n",
    "for batch_name in parent_folders:\n",
    "    _, subdirs, _ = next(os.walk(f\"../jump-scope/profiles/{batch_name}\"))\n",
    "    for plate_barcode in subdirs:\n",
    "        batch_path = f\"../jump-scope/profiles/{batch_name}/{plate_barcode}\"\n",
    "        for _, _, files in os.walk(batch_path):\n",
    "            for filename in files:\n",
    "                if filename.endswith(\"-dropout.csv\"):\n",
    "                    dropout_path = f\"{batch_path}/{plate_barcode}-dropout.csv\"\n",
    "                    dropout_df = pd.read_csv(dropout_path)\n",
    "                    dropout_df[\"batch_name\"] = batch_name\n",
    "                    df_list.append(dropout_df)\n",
    "\n",
    "collated_dropout_df = pd.concat(df_list)\n",
    "collated_dropout_df.to_csv(\"checkpoints/feature-dropouts-nuclei_cytoplasm_cells.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_graph_heatmap(df,col_list,row_list,cmap,title,figsize,xbreaklen=120,ybreaklen=180,xkcd=False):\n",
    "    full_col_list = []\n",
    "    full_col_list_for_labels = []\n",
    "    full_row_list= []\n",
    "    full_row_list_for_labels = []\n",
    "    for eachlen in range(len(col_list)+1):\n",
    "        full_col_list += sorted([str(sorted(x)) for x in list(itertools.combinations(col_list,eachlen))])\n",
    "        full_col_list_for_labels += sorted([(' + ').join(sorted(x)) for x in list(itertools.combinations(col_list,eachlen))])\n",
    "    for eachlen in range(len(row_list)+1):\n",
    "        full_row_list += sorted([str(sorted(x)) for x in list(itertools.combinations(row_list,eachlen))])\n",
    "        full_row_list_for_labels += sorted([(' + ').join(sorted(x)) for x in list(itertools.combinations(row_list,eachlen))])\n",
    "    square=pd.DataFrame(columns=full_col_list,index=full_row_list)\n",
    "    for _,row in df.iterrows():\n",
    "        sub_rows=[]\n",
    "        sub_cols=[]\n",
    "        for thing in row['dropout']:\n",
    "            if thing not in col_list:\n",
    "                sub_cols.append(thing)\n",
    "            else:\n",
    "                sub_rows.append(thing)\n",
    "        sub_rows.sort()\n",
    "        sub_cols.sort()\n",
    "        # square[str(sub_cols)][str(sub_rows)]=row['percent_replicating']*100\n",
    "        square.loc[str(sub_cols),str(sub_rows)] = row[\"percent_replicating\"]\n",
    "    square=square.fillna(0)\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    fig.set_facecolor(\"white\")\n",
    "    # if xkcd:\n",
    "    #     cmap=sns.light_palette(cmap,input='xkcd',as_cmap=True)\n",
    "    g=sns.heatmap(square,cmap=cmap,annot=True)\n",
    "    xlabels=['None']\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.tick_params(length=0)\n",
    "    for label in full_col_list_for_labels[1:]:\n",
    "        xlabels.append(textwrap.fill(label, width=xbreaklen/len(full_col_list_for_labels),break_long_words=False))\n",
    "    g.set_xticklabels(xlabels, rotation=0)\n",
    "    ylabels=['None']\n",
    "    for label in full_row_list_for_labels[1:]:\n",
    "        ylabels.append(textwrap.fill(label, width=ybreaklen/len(full_row_list_for_labels),break_long_words=False))\n",
    "    g.set_yticklabels(ylabels, rotation=0)\n",
    "    g.set_title(title)\n",
    "    # plt.savefig(f'figures/{title}.png',dpi=300)\n",
    "    \n",
    "    \n",
    "create_and_graph_heatmap(\n",
    "    dropout_df,\n",
    "    col_list=['Nuclei','Cytoplasm'],\n",
    "    row_list=['Cells'],\n",
    "    cmap='BuPu',\n",
    "    title = 'Mean Percent Replicating by Compartments Present for ALL profiles',\n",
    "    figsize=(10,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout groups\n",
    "# Basically, make matrix plots for profile groups\n",
    "# ie. compare dropouts for the same batch that have different site subsamples\n",
    "\n",
    "subsample_df = pd.read_csv('output/FoV-experiment-metadata.tsv', sep='\\t')\n",
    "\n",
    "dropout_df = pd.read_csv(\n",
    "    \"checkpoints/feature-dropouts-nuclei_cytoplasm_cells.csv\", \n",
    "    converters={'dropout':ast.literal_eval}\n",
    ")\n",
    "dropout_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DF that combines the dropout results with the subsample info\n",
    "\n",
    "batch_list = list(set(dropout_df.loc[:,\"batch_name\"]))\n",
    "plate_list = list(set(dropout_df.loc[:, \"assay_plate_barcode\"]))\n",
    "for plate in plate_list:\n",
    "    if plate == \"BRO0117033_20xb\":\n",
    "    # print(plate)\n",
    "        t = dropout_df.loc[dropout_df[\"assay_plate_barcode\"] == plate]\n",
    "        for subset in set(t[\"batch_name\"]):\n",
    "            subset_df = t[t[\"batch_name\"] == subset]\n",
    "            create_and_graph_heatmap(\n",
    "                subset_df,\n",
    "                col_list=['Nuclei','Cytoplasm'],\n",
    "                row_list=['Cells'],\n",
    "                cmap='BuPu',\n",
    "                title = f\"Percent replicating for {subset}\",\n",
    "                figsize=(10,6))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alt \n",
    "\n",
    "def create_and_graph_heatmap(df,col_list,row_list,ax_=None,xbreaklen=120,ybreaklen=180):\n",
    "    full_col_list = []\n",
    "    full_col_list_for_labels = []\n",
    "    full_row_list= []\n",
    "    full_row_list_for_labels = []\n",
    "    for eachlen in range(len(col_list)+1):\n",
    "        # This works out all of the combinations for the given col list (eg. nuclei, nuclei+cells...)\n",
    "        # Each combination is sorted so the label order is consistent, then the whole list itself is sorted\n",
    "        # itertools.combinations will only return combinations that are equal in length to each len,\n",
    "        # thus only combination lengths of 1 and 2 will be returned for col_list=[\"Nuclei\", \"Cells\"]\n",
    "        full_col_list += sorted([str(sorted(x)) for x in list(itertools.combinations(col_list,eachlen))])\n",
    "        # This generates the actual labels for above, ready to be displayed\n",
    "        full_col_list_for_labels += sorted([(' + ').join(sorted(x)) for x in list(itertools.combinations(col_list,eachlen))])\n",
    "    for eachlen in range(len(row_list)+1):\n",
    "        full_row_list += sorted([str(sorted(x)) for x in list(itertools.combinations(row_list,eachlen))])\n",
    "        full_row_list_for_labels += sorted([(' + ').join(sorted(x)) for x in list(itertools.combinations(row_list,eachlen))])\n",
    "    square=pd.DataFrame(columns=full_col_list,index=full_row_list)\n",
    "    for _,row in df.iterrows():\n",
    "        sub_rows=[]\n",
    "        sub_cols=[]\n",
    "        for thing in row['dropout']:\n",
    "            if thing not in col_list:\n",
    "                sub_cols.append(thing)\n",
    "            else:\n",
    "                sub_rows.append(thing)\n",
    "        sub_rows.sort()\n",
    "        sub_cols.sort()\n",
    "        square.loc[str(sub_cols),str(sub_rows)] = row[\"percent_replicating\"]\n",
    "    square=square.fillna(0)\n",
    "    if ax_ is None:\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "    fig.set_facecolor(\"white\")\n",
    "    g=sns.heatmap(square,annot=True)\n",
    "    xlabels=['None']\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.tick_params(length=0)\n",
    "    for label in full_col_list_for_labels[1:]:\n",
    "        xlabels.append(textwrap.fill(label, width=xbreaklen/len(full_col_list_for_labels),break_long_words=False))\n",
    "    g.set_xticklabels(xlabels, rotation=0)\n",
    "    ylabels=['None']\n",
    "    for label in full_row_list_for_labels[1:]:\n",
    "        ylabels.append(textwrap.fill(label, width=ybreaklen/len(full_row_list_for_labels),break_long_words=False))\n",
    "    g.set_yticklabels(ylabels, rotation=0)\n",
    "    g.set_title(title)\n",
    "    # plt.savefig(f'figures/{title}.png',dpi=300)\n",
    "    \n",
    "    \n",
    "create_and_graph_heatmap(\n",
    "    dropout_df,\n",
    "    col_list=['Nuclei','Cytoplasm'],\n",
    "    row_list=['Cells'],\n",
    "    cmap='BuPu',\n",
    "    title = 'Mean Percent Replicating by Compartments Present for ALL profiles',\n",
    "    figsize=(10,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_and_graph_heatmap(df,col_list,row_list,ax_=None,xbreaklen=120,ybreaklen=180):\n",
    "    full_col_list = []\n",
    "    full_col_list_for_labels = []\n",
    "    full_row_list= []\n",
    "    full_row_list_for_labels = []\n",
    "    for eachlen in range(len(col_list)+1):\n",
    "        full_col_list = sorted([y for x in range(len(col_list)+1) for y in list(set(itertools.combinations(col_list,x)))])\n",
    "        full_col_list += sorted([str(sorted(x)) for x in list(itertools.combinations(col_list,eachlen))])\n",
    "        # This generates the actual labels for above, ready to be displayed\n",
    "        sorted([y for x in range(len(col_list)+1) for y in list(set(itertools.combinations(col_list,x)))])\n",
    "        full_col_list_for_labels += sorted([(' + ').join(sorted(x)) for x in list(itertools.combinations(col_list,eachlen))])\n",
    "    for eachlen in range(len(row_list)+1):\n",
    "        full_row_list += sorted([str(sorted(x)) for x in list(itertools.combinations(row_list,eachlen))])\n",
    "        full_row_list_for_labels += sorted([(' + ').join(sorted(x)) for x in list(itertools.combinations(row_list,eachlen))])\n",
    "    square=pd.DataFrame(columns=full_col_list,index=full_row_list)\n",
    "    for _,row in df.iterrows():\n",
    "        sub_rows=[]\n",
    "        sub_cols=[]\n",
    "        for thing in row['dropout']:\n",
    "            if thing not in col_list:\n",
    "                sub_cols.append(thing)\n",
    "            else:\n",
    "                sub_rows.append(thing)\n",
    "        sub_rows.sort()\n",
    "        sub_cols.sort()\n",
    "        square.loc[str(sub_cols),str(sub_rows)] = row[\"percent_replicating\"]\n",
    "    square=square.fillna(0)\n",
    "    if ax_ is None:\n",
    "        fig, ax = plt.subplots(figsize=(15,15))\n",
    "    fig.set_facecolor(\"white\")\n",
    "    g=sns.heatmap(square,annot=True)\n",
    "    xlabels=['None']\n",
    "    ax.xaxis.tick_top()\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    ax.tick_params(length=0)\n",
    "    for label in full_col_list_for_labels[1:]:\n",
    "        xlabels.append(textwrap.fill(label, width=xbreaklen/len(full_col_list_for_labels),break_long_words=False))\n",
    "    g.set_xticklabels(xlabels, rotation=0)\n",
    "    ylabels=['None']\n",
    "    for label in full_row_list_for_labels[1:]:\n",
    "        ylabels.append(textwrap.fill(label, width=ybreaklen/len(full_row_list_for_labels),break_long_words=False))\n",
    "    g.set_yticklabels(ylabels, rotation=0)\n",
    "    g.set_title(title)\n",
    "    # plt.savefig(f'figures/{title}.png',dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('jump-scope')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "73b280186f56a0e7e1261797cbe1e0ce90ada53c728d4589dcde7f990cc23cb6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
