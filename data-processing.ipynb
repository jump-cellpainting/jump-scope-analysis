{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge experiment and fov metadata DFs together.\n",
    "\n",
    "fov = pd.read_csv(\"output/FoV-experiment-metadata.tsv\", sep=\"\\t\").drop(columns=(\"Batch\")).rename(columns={\"FoV_Batch\": \"Batch\"})\n",
    "\n",
    "orig = pd.read_csv('output/experiment-metadata-updated.csv')\n",
    "comb = pd.concat([fov, orig], ignore_index=True)\n",
    "comb[\"sites\"] = comb[\"Sites-SubSampled\"]\n",
    "comb[\"sites\"].fillna(comb[\"Images_per_well\"], inplace=True)\n",
    "comb.to_csv(\"output/all-profile-metadata.csv\", index_label='index', index=False)\n",
    "\n",
    "# Read new experiment df\n",
    "experiment_df = pd.read_csv(\"output/all-profile-metadata.csv\")\n",
    "\n",
    "experiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_moa_dataframe(experiment_metadata, profile_parent_dir, batch_col=\"Batch\", match_or_rep_or_both=\"replicating\", enable_sphering=\"both\"):\n",
    "    \"\"\"\n",
    "    batch_col is the name of the column to distinguish the profile parent folder. Eg. \"Scope1_MolDev_10X\" or \"1siteSubSample_Scope1_MolDev_10X\"\n",
    "    Output df will also use this batch_col name\n",
    "    \"\"\"\n",
    "    n_samples = 10000\n",
    "    n_replicates = 4  # number of sample replicates within each plate \n",
    "    metadata_common = 'Metadata_moa'\n",
    "    metadata_perturbation = 'Metadata_broad_sample'\n",
    "    group_by_feature = 'Metadata_pert_iname'\n",
    "\n",
    "    corr_replicating_list = list()\n",
    "    corr_matching_list = list()\n",
    "\n",
    "    for ind, a_vendor in enumerate(experiment_metadata[\"Vendor\"].unique()):\n",
    "        print(f\"Processing {a_vendor}\")\n",
    "        vendor_data = experiment_metadata.loc[experiment_metadata[\"Vendor\"] == a_vendor]\n",
    "        for a_batch in vendor_data[batch_col].unique():\n",
    "            batch_data = vendor_data.loc[vendor_data[batch_col] == a_batch]\n",
    "            for a_plate in batch_data[\"Assay_Plate_Barcode\"].unique():\n",
    "                # plate_data = batch_data.loc[batch_data[\"Assay_Plate_Barcode\"] == a_plate]\n",
    "                data_path = os.path.join(profile_parent_dir, a_batch, a_plate, a_plate+\"_normalized_feature_select_negcon_batch.csv.gz\")\n",
    "                load_data = pd.read_csv(data_path)\n",
    "                # print(data_path)\n",
    "                try:\n",
    "                    if match_or_rep_or_both.casefold() == \"replicating\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "                        if enable_sphering.casefold() == \"yes\" or enable_sphering.casefold() == \"both\":\n",
    "                            sphere_bool = True\n",
    "                            replicate_corr_sphere, null_replicating_sphere, prop_95_replicating_sphere, value_95_replicating_sphere = utilssphering.calculate_percent_replicating_MOA(\"\", \"\", data_df=load_data)\n",
    "                            corr_replicating_list.append(pd.DataFrame({'Vendor': a_vendor,\n",
    "                                                                        batch_col: a_batch,\n",
    "                                                                        'Assay_Plate_Barcode': a_plate,\n",
    "                                                                        'Replicating':[replicate_corr_sphere],\n",
    "                                                                        'Null_Replicating':[null_replicating_sphere],\n",
    "                                                                        'Percent_Replicating':prop_95_replicating_sphere,\n",
    "                                                                        'Value_95':value_95_replicating_sphere,\n",
    "                                                                        'sphering': sphere_bool}, index=[ind]))\n",
    "\n",
    "                        if enable_sphering.casefold() == \"no\" or enable_sphering.casefold() == \"both\": \n",
    "                            sphere_bool = False\n",
    "                            plate_df = utils.remove_negcon_empty_wells(load_data)\n",
    "                            replicate_corr = list(utils.corr_between_replicates(plate_df, group_by_feature))\n",
    "                            null_replicating = list(utils.corr_between_non_replicates(plate_df, n_samples=n_samples, n_replicates=n_replicates, metadata_compound_name=group_by_feature))\n",
    "                            prop_95_replicating, value_95_replicating = utils.percent_score(null_replicating, replicate_corr, how='right')\n",
    "                            corr_replicating_list.append(pd.DataFrame({'Vendor': a_vendor,\n",
    "                                                                        batch_col: a_batch,\n",
    "                                                                        'Assay_Plate_Barcode': a_plate,\n",
    "                                                                        'Replicating':[replicate_corr],\n",
    "                                                                        'Null_Replicating':[null_replicating],\n",
    "                                                                        'Percent_Replicating':prop_95_replicating,\n",
    "                                                                        'Value_95':value_95_replicating,\n",
    "                                                                        'sphering': sphere_bool}, index=[ind]))\n",
    "\n",
    "                    if match_or_rep_or_both.casefold() == \"matching\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "                        if enable_sphering.casefold() == \"yes\" or enable_sphering.casefold() == \"both\":\n",
    "                            sphere_bool = True\n",
    "                            matching_corr_sphere, null_matching_sphere, prop_95_matching_sphere, value_95_matching_sphere = utilssphering.calculate_percent_matching_MOA(\"\", \"\", data_df=load_data)\n",
    "                            corr_matching_list.append(pd.DataFrame({'Vendor': a_vendor,\n",
    "                                                                    batch_col: a_batch,\n",
    "                                                                    'Assay_Plate_Barcode': a_plate,\n",
    "                                                                    'Matching':[matching_corr_sphere],\n",
    "                                                                    'Null_Matching':[null_matching_sphere],\n",
    "                                                                    'Percent_Matching':prop_95_matching_sphere,\n",
    "                                                                    'Value_95':value_95_matching_sphere,\n",
    "                                                                    'sphering': sphere_bool}, index=[ind]))\n",
    "                        \n",
    "                        if enable_sphering.casefold() == \"no\" or enable_sphering.casefold() == \"both\": \n",
    "                            sphere_bool = False\n",
    "                            plate_df = utils.remove_negcon_empty_wells(load_data)\n",
    "                            matching_corr = list(utils.corr_between_perturbation_pairs(plate_df, 'Metadata_moa', 'Metadata_broad_sample'))\n",
    "                            null_matching = list(utils.corr_between_perturbation_non_pairs(plate_df, n_samples=n_samples, metadata_common=metadata_common, metadata_perturbation=metadata_perturbation))\n",
    "                            prop_95_matching, value_95_matching = utils.percent_score(null_matching, matching_corr, how='right')\n",
    "                            corr_matching_list.append(pd.DataFrame({'Vendor': a_vendor,\n",
    "                                                                    batch_col: a_batch,\n",
    "                                                                    'Assay_Plate_Barcode': a_plate,\n",
    "                                                                    'Matching':[matching_corr],\n",
    "                                                                    'Null_Matching':[null_matching],\n",
    "                                                                    'Percent_Matching':prop_95_matching,\n",
    "                                                                    'Value_95':value_95_matching,\n",
    "                                                                    'sphering': sphere_bool}, index=[ind]))\n",
    "                except:\n",
    "                    print(f\"Passed: {data_path}\")\n",
    "                    pass\n",
    "    # Concatenate the data\n",
    "    if match_or_rep_or_both.casefold() == \"replicating\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "        corr_replicating_df = pd.concat(corr_replicating_list, ignore_index=True)\n",
    "    if match_or_rep_or_both.casefold() == \"matching\" or match_or_rep_or_both.casefold() == \"both\":\n",
    "        corr_matching_df = pd.concat(corr_matching_list, ignore_index=True)\n",
    "                \n",
    "    # Merge metadata with output dataframes\n",
    "    merge_columns = ['Vendor', batch_col, 'Assay_Plate_Barcode']\n",
    "    if match_or_rep_or_both.casefold() == \"both\":\n",
    "        corr_replicating_df = experiment_metadata.merge(corr_replicating_df, how=\"inner\", on=merge_columns)\n",
    "        corr_matching_df = experiment_metadata.merge(corr_matching_df, how=\"inner\", on=merge_columns)\n",
    "        return corr_replicating_df, corr_matching_df\n",
    "    if match_or_rep_or_both.casefold() == \"replicating\":\n",
    "        return experiment_metadata.merge(corr_replicating_df, how=\"inner\", on=merge_columns)\n",
    "    elif match_or_rep_or_both.casefold() == \"matching\":\n",
    "        return experiment_metadata.merge(corr_matching_df, how=\"inner\", on=merge_columns)\n",
    "\n",
    "df_replicating, df_matching = create_moa_dataframe(experiment_df, \"../jump-scope/profiles/\", match_or_rep_or_both=\"both\", enable_sphering=\"both\")\n",
    "# df = create_moa_dataframe(pd.read_csv('output/experiment-metadata.tsv', sep='\\t'), \"../jump-scope/profiles/\", match_or_rep_or_both=\"replicating\", enable_sphering=\"no\")\n",
    "\n",
    "# df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_total_cell_counts(df, profile_path):\n",
    "    out_df = df.copy()\n",
    "    out_df[\"cell_count\"] = \"\"\n",
    "    for i in df.index:\n",
    "        batch = df.loc[i, \"Batch\"]\n",
    "        barcode = df.loc[i, \"Assay_Plate_Barcode\"]\n",
    "        load_path = os.path.join(profile_path, batch, barcode, f\"{barcode}_normalized_negcon.csv.gz\")\n",
    "        load_df = pd.read_csv(load_path)\n",
    "        try:\n",
    "            sum_cells = sum(load_df.loc[:,\"Metadata_Count_Cells\"])\n",
    "        except:\n",
    "            # In case a profile is missing cell count data\n",
    "            sum_cells = np.nan\n",
    "        out_df.loc[i, \"cell_count\"] = sum_cells\n",
    "    return out_df\n",
    "\n",
    "df_replicating = add_total_cell_counts(df_replicating, \"../jump-scope/profiles/\")\n",
    "df_matching = add_total_cell_counts(df_matching, \"../jump-scope/profiles/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sites and subsample columns\n",
    "df_replicating.loc[df_replicating[\"Sites-SubSampled\"].isnull(), \"Sites-SubSampled\"] = df_replicating[\"Images_per_well\"]\n",
    "df_replicating[\"Sites-SubSampled\"] = pd.to_numeric(df_replicating[\"Sites-SubSampled\"], downcast=\"integer\")\n",
    "\n",
    "df_matching.loc[df_matching[\"Sites-SubSampled\"].isnull(), \"Sites-SubSampled\"] = df_matching[\"Images_per_well\"]\n",
    "df_matching[\"Sites-SubSampled\"] = pd.to_numeric(df_matching[\"Sites-SubSampled\"], downcast=\"integer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checkpoint save\n",
    "\n",
    "if not os.path.isdir(\"checkpoints\"):\n",
    "    os.mkdir(\"checkpoints\")\n",
    "\n",
    "df_replicating.to_csv(\"checkpoints/moa-replicating-sphering.csv\", index_label='index', index=False)\n",
    "\n",
    "df_matching.to_csv(\"checkpoints/moa-matching-sphering.csv\", index_label='index', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns so \n",
    "df_replicating = df_replicating.rename(columns={\"Value_95\": \"value_95_replicating\"})\n",
    "# df_replicating[\"spinning-disc\"] = df_replicating[\"spinning-disc\"].fillna(0)\n",
    "df_matching = df_matching.rename(columns={\"Value_95\": \"value_95_matching\"})\n",
    "# df_matching[\"spinning-disc\"] = df_matching[\"spinning-disc\"].fillna(0)\n",
    "\n",
    "# print(df_replicating.shape, df_matching.shape)\n",
    "# merge_cols = [i for i in df_matching.columns if \"matching\" not in i.lower()]\n",
    "\n",
    "merge_cols = ['Vendor',\n",
    " 'Batch',\n",
    " 'Plate_Map_Name',\n",
    " 'Assay_Plate_Barcode',\n",
    " 'Modality',\n",
    " 'Images_per_well',\n",
    " 'Binning',\n",
    " 'Magnification',\n",
    " 'Number_of_channels',\n",
    " 'z_plane',\n",
    " 'Anomaly',\n",
    " 'spinning-disc',\n",
    " 'vs-brightfield',\n",
    " 'sites',\n",
    " \"BF_Zplanes\",\n",
    " \"dry-immersion\",\n",
    " \"vs-brightfield\",\n",
    " \"simultaneous-excitation\",\n",
    " \"cell_count\",\n",
    " \"sites\",\n",
    " \"aperture\",\n",
    " 'sphering']\n",
    "\n",
    "# match_rep_df = df_replicating.merge(df_matching, on=merge_cols, how=\"left\")[[\"Percent_Replicating\"]]\n",
    "\n",
    "match_rep_df = pd.merge(df_replicating, df_matching, on=merge_cols, how=\"inner\")\n",
    "match_rep_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement QC information into dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "90bd059e05f79fb9b7cf5d2b1dae6ea26ca779772e058f49dd8fbe1978749df0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
